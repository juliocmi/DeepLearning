# -*- coding: utf-8 -*-
"""LTSM Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t0DEwa6pgzHwQZG8mZZiOPOd-iYnQws5

# LTSM Project
---

- **Notebook:** Julio César Martínez
- **Posición:** Data Scientist
- **Fecha:** 21-Ene-24

# Introducción
---

El análisis de sentimiento se refiere a un aspecto del campo de procesamiento del lenguaje natural y se dedica exclusivamente a comprender opiniones subjetivas o sentimientos agregados de una variedad de fuentes sobre un solo tema.

Puesto en un contexto comercial, el análisis de sentimiento se refiere a herramientas que identifican y extrapolan información de opiniones y luego mejoran las operaciones comerciales. Esto se hace con la ayuda de una variedad de algoritmos que profundizan en el subcontexto de las opiniones e intentan comprender las actitudes con respecto a un producto o cualquier elemento específico.

El análisis de sentimiento tiene que ver con la extracción de opiniones para comprender el razonamiento del público en general, lo que permite a las empresas examinar el posicionamiento del producto. El análisis de sentimiento se utiliza en muchas áreas diferentes:

- Analítica de productos
- Estudios de mercado
- Hiperpersonalización
- Manejo de reputación
- Percepciones en las relaciones públicas
- Orientación precisa de los clientes
- Reseñas de productos
- Comentarios sobre el producto
- Servicio al cliente eficiente

El análisis de sentimiento juega un papel muy importante para ayudar a las empresas a desarrollar productos y servicios más inteligentes que aborden específicamente las necesidades de los clientes.

**MODELO RECURRENTE**

Dicho lo anterior, en este proyecto estarémos realizando un análisis de sentimientos para una página de películas llamada IMBD, para ello, utilizaremos un modelo recurrente LTSM (long short term memory) donde introducimos información a una capa y después volvemos a meter información a la misma.

# Tabla de Contenido
---

1. Cargar los datos
2. Exploración de datos
3. Preprocesamiento de datos
4. Crear Red Neuronal
5. Entrenar y evaluar modelo
6. Conclusiones

# Proyecto LTSM
---

Para este proyecto utilizaremos un dataset de keras y es con el que vamos a trabajar de manera sencilla para demostrar algunos de nuestros conocimientos en este campo de la inteligencia artificial.

## Cargar datos

cargar librerías
"""

import pandas as pd
import numpy as np
import tensorflow as tf

from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, LSTM, Embedding, SimpleRNN
#from tensorflow.keras.layers.embeddings import Embeding

"""cargar datos"""

# definimos número de palabras para evitar la complegidad computacional, el set original se compone de 88 mil palabras.
numeropalabras = 10000
(X_train, y_train),(X_test,y_test) = imdb.load_data(num_words=numeropalabras)

"""## Exploración de datos

tamaño del dataset
"""

print('set de entrenamiento:   ', X_train.shape)
print('target de entrenamiento:', y_train.shape)
print('set de prueba:   ', X_test.shape)
print('target de prueba:', y_test.shape)

"""revisar elemento en X_train"""

# Commented out IPython magic to ensure Python compatibility.
# %pprint

X_train[150]

"""**Observacion**

Al explorar el elemento 150 encontramos una lista de números que nos índican cuál es el elemento que más se repite dentro del corpus de palabras. Por ejemplo, el 1 significa que es la palabra más repetida, el 5 la quinta palabra más utilizada, etc.

Hay un detalle con este dataset y es que la librería keras espera corpus de palabras completas, por ejemplo, keras espera un corpus de 100 palabras pero si solo le dimos 90 el resto de palabras para llegar a 100 las denominaría en ceros. Este fenomeno recibe el nombre de padding y para evitarlo keras desfasa cada 3 elementos las palabras, por lo tanto, si queremos ver la palabra más popular como se menciona en el párrafo anterior, entonces debemos búscar la palabra número 3 y no la 1 como se menciona.
"""

# llamar a word_index
word_to_index = imdb.get_word_index()
# índice de la palabra bad
print('índice de la palabra bad:', word_to_index['bad'])

"""La palabra **bad** es la número 75 más éxitoza o más repetitiva dentro de todas las reseñas que se muestran. Ahora lo que necesitamos es poder dar un número y que nos devuelva la palabra, para ello debemos cambiar la relación de palabras a números."""

index_to_word={index:word for (word,index) in word_to_index.items()}

word_to_index['bad']

"""armar lista con las palabras más populares"""

[index_to_word[i] for i in range(1,51)]

"""obtener el corpus del elemento 123 de la lista"""

" ".join([index_to_word.get(i-3,"?") for i in X_train[123]])

"""según el texto, verificamos si es una relación positiva (1) o negativa (0)"""

y_train[123]

"""## Preprocesamiento de Datos
---

Todo el trabajo que realizamos anteriormente fue para poder comprender mejor de qué se tratan los elementos o reseñas del dataset, sin embargo, a keras le interesan más los números.

Definir palabras por reseña en 200
"""

numpal=200
X_train = pad_sequences(
    X_train,
    maxlen=numpal
    ) #<-- truncamos las reseñas
X_train.shape # <-- nuevo split

X_test = pad_sequences(
    X_test,
    maxlen=numpal
    )
X_test.shape

"""Dividir los datos"""

X_test, X_val, y_test, y_val = train_test_split(
    X_test,
    y_test,
    random_state=11,
    test_size=0.20
    )

X_test.shape

X_val.shape

y_val.shape

"""## Crear Red Neuronal
---
"""

rnn = Sequential() # <-- instanciar modelo
rnn.add(           # <-- capa embeding
        Embedding(
        input_dim=numeropalabras,
        output_dim=128,
        input_length=numpal
        )
    )
rnn.add( # <-- capa de recursión
    LSTM(
        units=128,
        dropout=0.2,
        recurrent_dropout=0.2
        )
    )
rnn.add( # <-- capa densa
    Dense(
        units=1,
        activation='sigmoid'
        )
    )
rnn.compile( # <-- compilar la red
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
    )

rnn.summary()

"""## Entrenar y evaluar modelo
---

Usar fit para entrenar modelo
"""

rnn.fit(
    X_train,
    y_train,
    epochs=10,
    batch_size=32,
    validation_data=(
        X_test,
        y_test
        )
    )

rnn.evaluate(X_val, y_val)

"""## Conclusiones

Después de completar con éxito cada uno de los pasos para desarrollar nuestro modelo de recursión, llegamos a los siguientes puntos:

- El modelo se desarrolló con un dataset propio de la librería de keras, el cual contiene hasta 80 mil reseñas de películas.
- Por temas de complejidad computacional, nuestro modelo se entrenó solo con 10 mil reseñas.
- El modelo LSTM se construyó con solo 3 capas debido a la complejidad computacional.
- El modelo logró una exactitud final de 85% mientras que se logró una función de pérdida de hasta un 69%.
- Lo anterior significa que, aunque el modelo cuenta con una buena precisión,
 aún no es capaz de distingir correctamente entre comentarios positivos o negativos que existen dentro de las reseñas.
- Algunas recomendaciones para mejorar el modelo incluyen:
  - Entrenar al modelo con más o menos datos.
  - Cambiar el rango de validación.
  - Aumentar capas de entrenamiento.

Por lo pronto nos quedaremos con este resultado, en otro proyecto estarémos utilizando esta red implementando mejoras para lograr mejores proyecciones en nuestro objetivo.
"""
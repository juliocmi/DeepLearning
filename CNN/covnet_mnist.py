# -*- coding: utf-8 -*-
"""COVNET - MNIST

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h2Z09nR5Gw_eQP9d0tUVDueIMbCR395A

# CONVNET Study Case
---

- **Notebook:** Julio César Martínez I.
- **Posición:** Data Scientist
- **Fecha:** 15-Ene-2024

# Apache Licence
---
Copyright [15-Ene-2024] [Julio César Martínez I.]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

# Introducción
---

Para este proyecto vamos a trabajar con un dataset que se llama **MNIST** que se compone de un total de 70,000 muestras de dígitos etiquetadas. Cada muestra es un dígito en blanco y negro de 28 x 28 píxeles y cada píxel es un valor de 0 a 255 representando la intensidad o sombra de ese píxel. La intención de este proyecto es construir una **Red Neuronal Convolucional** la cual nos devolverá una **Clasificación Probabilística**, es decir, para cada imágen del dígito el modelo nos devolverá un arreglo de 10 probabilidades, cada una índicando la posibilidad de que el dígito pertenesca a uno de los dígitos de 0 a 9 y la clase con la probabilidad más alta es el valor predicho.

# Librerías Requeridas
---

- pandas
- numpy
- scikit-learn
- tensorflow
- keras

# Tabla de Contenido

1. Cargar el Dataset

# Cargar el Dataset

Importando librerías y dataset **MNIST**
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

import seaborn as sns
sns.set(font_scale=2)

import numpy as np

from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D
from IPython.display import Image

"""Cargando los datos en train y test"""

(X_train,y_train),(X_test,y_test)=mnist.load_data()

"""# Proyecto - COVNET

## Exploración de Datos

Inspeccionando tamaño del dataset
"""

print('Conjunto de Entrenamiento:', X_train.shape)
print('Conjunto de Objetivo:', y_train.shape)

print('Conjunto de Prueba:', X_test.shape)
print('Conjunto del Target de Prueba:', y_test.shape)

"""Visualizando digitos aleatorios"""

# imprimir 24 digitos aleatorios
indice = np.random.choice(
    np.arange(
        len(
            X_train
            )
        ),
    24,
    replace=False
    )
indice

fig,ax=plt.subplots(nrows=4,ncols=6,figsize=(16,9))

for item in zip(ax.ravel(), X_train[indice], y_train[indice]):
  ax,image,target=item
  ax.imshow(image,cmap=plt.cm.gray_r)
  ax.set_xticks([])
  ax.set_yticks([])
  ax.set_title(target)
plt.tight_layout()

"""## Preparar Datos

Cambiando figura de Xtrain y Xtest
"""

X_train = X_train.reshape((60000,28,28,1))
X_train.shape

X_test = X_test.reshape((10000,28,28,1))
X_test.shape

"""Normalizando los datos"""

X_train = X_train.astype("float32")/255
X_test = X_test.astype("float32")/255

"""Realizando one-hot encoding"""

y_train = to_categorical(y_train)
y_train.shape

y_train[0]

y_test = to_categorical(y_test)
y_test.shape

y_test[0]

"""## Creando Red Neuronal Convolucional

Instanciando modelo
"""

cnn = Sequential()

cnn.add(Conv2D(filters=64,kernel_size=(3,3),activation="relu", input_shape=(28,28,1)))

cnn.add(MaxPooling2D(pool_size=(2,2)))

cnn.add(Conv2D(filters=128,kernel_size=(3,3), activation="relu"))

cnn.add(MaxPooling2D(pool_size=(2,2)))

"""Aplicando aplanado de resultados"""

cnn.add(Flatten())

cnn.add(Dense(units=128, activation='relu'))

cnn.add(Dense(units=10, activation='softmax'))

"""Imprimir resultado"""

cnn.summary()

# --> estructura del modelo
plot_model(
    cnn,
    to_file="covnet.png",
    show_shapes=True,
    show_layer_names=True
    )
Image(filename="covnet.png")

# --> compilando modelo
cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

"""## Entrenar y Evaluar el Modelo

Entrenando modelo con fit
"""

cnn.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)

"""Evaluando modelo"""

loss, acuracy = cnn.evaluate(X_test, y_test)

"""Hacer predicciones"""

predicciones = cnn.predict(X_test)

# --> elemento y_test
y_test[0]

# --> elemento del modelo
for index, probability in enumerate(predicciones[0]):
  print(f'{index}: {probability:.10%}')

# --> predicciones incorrectas
images = X_test.reshape((10000,28,28))
incorrect_predictions=[]

for i, (p,e) in enumerate(zip(predicciones,y_test)):
  predicted, expected = np.argmax(p), np.argmax(e)

  if predicted != expected:
    incorrect_predictions.append((i, images[i], predicted, expected))

# --> longitud de lista
print('No de errores:', len(incorrect_predictions))

# --> visualizando predicciones incorrectas

fig, ax = plt.subplots(nrows=4, ncols=6, figsize=(12,8))

for ax, item in zip(ax.ravel(), incorrect_predictions):
  index, image, predicted, expected = item
  ax.imshow(image, cmap=plt.cm.gray_r)
  ax.set_xticks([])
  ax.set_yticks([])
  ax.set_title(f'index: {index}\np: {predicted}; e: {expected}')
plt.tight_layout()

# --> armar una función para un listado de probabilidades incorrectas

def muestraprob(prediction):
  for index, probability, in enumerate(prediction):
    print(f'{index}: {probability:.10%}')

# --> probabilidades incorrectas
muestraprob(predicciones[726])

"""# Conclusiones

Después de pasar un tiempo entrenando y probando nuestra red convolucional llegamos a las siguientes conclusiones:

- Se pueden observar toda la gama de números que tienen errores, por ejemplo, en el primer número el modelo predijo un 3 pero en realidad esperábamos un 5. El mismo caso se aplica para el último número el cual el modelo predijo un 2 pero en realidad esperába un 1. De esta manera podemos darnos cuenta que incluso para nosotros como seres humanos nos es difícil también reconocer algunos números.
- La red convolucional se entrenó con al menos 5 epochs.
- Se obtuvieron 79 errores en las predicciones del modelo.
- El modelo funciona con el 99.9% de exactitud y se dejó al menos un 10% para datos de validación.
- Para este modelo se utilizaron 3 capas de convoluciones y 3 capas de Flatten.
"""